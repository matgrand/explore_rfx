{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's explore the RFX MDSplus tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing and setting up stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import MDSplus as mds\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys, os, time, random\n",
    "from tqdm import tqdm\n",
    "import h5py as h5\n",
    "print(f'Python version: {sys.version}')\n",
    "print(f'MDSplus version: {mds.__version__}')\n",
    "np.set_printoptions(precision=3, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#color the terminal output\n",
    "def pick_random_color():\n",
    "    return '\\033[38;5;{}m'.format(random.randint(8, 230))\n",
    "ENDC = '\\033[0m'\n",
    "ERR = '\\033[91m'+ 'ERR: '\n",
    "OK = '\\033[92m' \n",
    "WARN = '\\033[93m'+ 'WARN: '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the shot number and tree\n",
    "SHOT = 30810\n",
    "rfx = mds.Tree('rfx', SHOT, 'readonly') # open the tree read-only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traversing the tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# traverse the tree, use MAX_DEPTH to limit the depth of the tree to traverse\n",
    "# othwerwise the script will run for about 10 minutes\n",
    "MAX_DEPTH = 5 # maximum depth of the tree to traverse\n",
    "COLORS = [pick_random_color() for i in range(MAX_DEPTH)]\n",
    "\n",
    "usage_depth, usage_breadth = {},{}\n",
    "\n",
    "def traverse_tree_depth_first(max_depth, node, level=0, path='', node_type='child'):\n",
    "    try: \n",
    "        if level >= max_depth: return # stop if the maximum depth is reached\n",
    "        if node_type == 'child': node_name = node.node_name.upper()\n",
    "        elif node_type == 'member': node_name = node.node_name.lower()\n",
    "        else: raise\n",
    "        path = path + '/' + COLORS[level] + node_name + ENDC # add the node name\n",
    "        print(f'{path}:{node.decompile()}') \n",
    "        # get the usage/type of the node\n",
    "        try: usage_depth[str(node.usage)] += 1\n",
    "        except: usage_depth[str(node.usage)] = 1\n",
    "        # go through the children and members of the node\n",
    "        for child in node.getChildren(): # get the children of the node\n",
    "            traverse_tree_depth_first(max_depth, child, level + 1, path, 'child')\n",
    "        for member in node.getMembers(): # get the members of the node\n",
    "            traverse_tree_depth_first(max_depth, member, level + 1, path, 'member')\n",
    "    except Exception as e:\n",
    "        print(path + 'ERR:' + str(e))\n",
    "        pass\n",
    "\n",
    "# do the same but without recursion\n",
    "def traverse_tree_breadth_first(max_depth, head_node):\n",
    "    curr_nodes = [head_node]\n",
    "    for d in range(max_depth):\n",
    "        print('Depth:', d)\n",
    "        next_nodes = []\n",
    "        for node in curr_nodes:\n",
    "            try:\n",
    "                preprint = COLORS[d] + \"   \" * d + node.node_name + ENDC\n",
    "                print(f'{preprint}:{node.decompile()}') # print the node\n",
    "                # get the usage/type of the node\n",
    "                try: usage_breadth[str(node.usage)] += 1\n",
    "                except: usage_breadth[str(node.usage)] = 1\n",
    "                # get the children of the node\n",
    "                for child in node.getChildren():\n",
    "                    next_nodes.append(child)\n",
    "                # get the members of the node\n",
    "                for member in node.getMembers():\n",
    "                    next_nodes.append(member)\n",
    "            except: pass\n",
    "        curr_nodes = next_nodes\n",
    "        \n",
    "head_node = rfx.getNode('\\\\TOP.RFX') # get the top node\n",
    "\n",
    "# test the functions, uncomment to run\n",
    "# traverse_tree_depth_first(MAX_DEPTH, head_node) # traverse the tree depth-first\n",
    "# traverse_tree_breadth_first(MAX_DEPTH, head_node) # traverse the tree breadth-first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Usage depth: {usage_depth}')\n",
    "print(f'Usage breadth: {usage_breadth}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "previous cell full depth: 'STRUCTURE': 8776, 'SUBTREE': 78, 'DEVICE': 642, 'ACTION': 1098, 'NUMERIC': 47760, 'TEXT': 17269, 'SIGNAL': 20904, 'ANY': 29, 'AXIS': 215"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'top nodes: {[n.node_name for n in head_node.getChildren()]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring Signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = '\\\\TOP.RFX.MHD.***' # *** means all nodes at this level\n",
    "# search_space = '\\\\TOP.RFX.EDA.***' # * means all nodes at this level\n",
    "# search_space = '\\\\TOP.RFX.***' # whole rfx tree\n",
    "signal_nodes = rfx.getNodeWild(search_space, 'Signal') # get all nodes with the name 'Signal'\n",
    "print(f'Found {len(signal_nodes)} of the type Signal in the search space {search_space}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # filter out the nodes without the data\n",
    "# data_signals = []\n",
    "# for node in tqdm(signal_nodes, leave=False):\n",
    "#     try: data = node.data(); data_signals.append(node)\n",
    "#     except: pass\n",
    "# print(f'Found {len(data_signals)}/{len(signal_nodes)} signals with data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # keep only the signals with raw data\n",
    "# raw_signals = []\n",
    "# for node in tqdm(signal_nodes, leave=False):\n",
    "#     try: data = node.raw_of().data(); raw_signals.append(node)\n",
    "#     except: pass\n",
    "# print(f'Found {len(raw_signals)}/{len(data_signals)} signals with raw data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # extract data from the signals and plot them\n",
    "# MAX_LOAD = 0 #10 #np.inf\n",
    "# MAX_LOAD = min(MAX_LOAD, len(raw_signals))\n",
    "# # select MAX_LOAD random signals\n",
    "# signals = random.sample(raw_signals, MAX_LOAD)\n",
    "# for node in (signals):\n",
    "#     signal = node.data()\n",
    "#     times = node.dim_of().data()\n",
    "#     unit = node.getUnits()\n",
    "#     full_path = node.getFullPath()\n",
    "#     try: node_help = node.getHelp()\n",
    "#     except: node_help = ''\n",
    "#     if signal.shape != times.shape:\n",
    "#         print(f'{full_path} has mismatched signal and time shapes')\n",
    "#         continue\n",
    "#     # plot the signal\n",
    "#     plt.figure()\n",
    "#     plt.plot(times, signal)\n",
    "#     plt.title(f'{full_path} [{unit}]\\n{node_help}')\n",
    "#     plt.xlabel('Time [s]')\n",
    "#     plt.ylabel('Signal')\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_nodes = rfx.getNodeWild(search_space, 'Text') # get all the 'TEXT' nodes\n",
    "# print(f'Found {len(text_nodes)} of the type Text in the search space {search_space}')\n",
    "# # print all the text nodes\n",
    "# for node in text_nodes:\n",
    "#     try: print(f'{node.getFullPath()}={node.data()}')\n",
    "#     except: pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert tree in HDF5 format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HDF5_FILE = f'rfx_{SHOT}.hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_tree_hdf5(head_node, new_tree_file):\n",
    "    #explore all the tree and save the data to the hdf5 file\n",
    "    max_depth = 4\n",
    "    with h5.File(new_tree_file, 'w') as f:\n",
    "        curr_nodes = [(head_node,'child')]\n",
    "        tot_nodes_explored, valid_nodes, signal_nodes = 0, 0, 0\n",
    "        for d in range(max_depth):\n",
    "            print('Depth:', d)\n",
    "            next_nodes = []\n",
    "            for node, node_type in curr_nodes:\n",
    "                tot_nodes_explored += 1\n",
    "                full_path = str(node.getFullPath())[10:]#.lower() # remove the \\\\TOP.RFX prefix\n",
    "                full_path = full_path.replace('.', '/') #convert . to /\n",
    "                \n",
    "                try: # get the children and members of the node\n",
    "                    for child in node.getChildren(): next_nodes.append((child, 'child'))\n",
    "                    for member in node.getMembers(): next_nodes.append((member, 'member'))\n",
    "                except: pass # do nothing if the node has no children or members\n",
    "                \n",
    "                usage = str(node.usage)\n",
    "                \n",
    "                # check if the node has data\n",
    "                try: data = node.data()\n",
    "                except: data = None\n",
    "                \n",
    "                #check if the node has time\n",
    "                try: times = node.dim_of().data()\n",
    "                except: times = None\n",
    "                \n",
    "                # VARIOUS CHECKS\n",
    "                if usage == 'SIGNAL' and data is None: # signal without data\n",
    "                    print(f'{full_path} is signal but has no data'); continue\n",
    "                if usage == 'SIGNAL' and data is not None and times is None: # signal with data but no time\n",
    "                    print(f'{full_path} is signal with data but no time: data: {data}'); continue\n",
    "                if usage == 'NUMERIC' and data is None: # numeric without data\n",
    "                    print(f'{full_path} is numeric but has no data'); continue\n",
    "                if data is not None and times is not None: # node with data and time\n",
    "                    if data.shape != times.shape: # mismatched signal and time shapes, multidimensional signals are notable exceptions, but for now we skip them\n",
    "                        print(f'{full_path} has mismatched signal and time shapes, {data.shape} != {times.shape}'); continue\n",
    "                    if usage != 'SIGNAL': # not a signal but has data and time\n",
    "                        print(f'{full_path} is not signal but has data and time'); continue\n",
    "                        \n",
    "                valid_nodes += 1 # valid node\n",
    "                \n",
    "                if usage in ['SIGNAL', 'NUMERIC']: # save the data to the hdf5 file\n",
    "                    signal_nodes += 1\n",
    "                    if data is not None: f.create_dataset(full_path, data=data)\n",
    "                    if times is not None: f.create_dataset(full_path + '/times', data=times)\n",
    "                \n",
    "                # print(f'{full_path}:{usage.lower()}')\n",
    "                \n",
    "                # print(f'{valid_nodes}/{tot_nodes_explored} with usage {usage} and data {data}')\n",
    "                \n",
    "            curr_nodes = next_nodes # update the current nodes\n",
    "    \n",
    "    print(f'Valid nodes: {valid_nodes}/{tot_nodes_explored}, {valid_nodes/tot_nodes_explored*100:.2f}%')\n",
    "    print(f'Signal nodes: {signal_nodes}/{valid_nodes}, {signal_nodes/valid_nodes*100:.2f}%')\n",
    "# test the function\n",
    "# convert_tree_hdf5(rfx.getNode('\\\\RFX::TOP.RFX'), HDF5_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to check if the node has data, time, children or members\n",
    "def hasData(node):\n",
    "    try: _ = node.data(); return True\n",
    "    except: return False\n",
    "\n",
    "def hasTime(node):\n",
    "    try: _ = node.dim_of().data(); return True\n",
    "    except: return False\n",
    "    \n",
    "def hasChildren(node):\n",
    "    try: return len(node.getChildren()) > 0\n",
    "    except: return False\n",
    "\n",
    "def hasMembers(node):\n",
    "    try: return len(node.getMembers()) > 0\n",
    "    except: return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a list of nodes to skip, because they trow segmentation fault\n",
    "SEG_FAULT_NODES = [\n",
    "    '\\\\RFX::TOP.RFX.MHD.MHD_BR:CPCI_1:ADC:TR10_1:CLOCK_SOURCE',\n",
    "    '\\\\RFX::TOP.RFX.MHD.MHD_BR:CPCI_1:ADC:TR10_10:CLOCK_SOURCE',\n",
    "    '\\\\RFX::TOP.RFX.DIAG.DTER.DTER_RAW.TIMING:DECODER_01.CHANNEL_3:SPECIAL_GATE',\n",
    "    '\\\\RFX::TOP.RFX.DIAG.DTER.DTER_RAW.TIMING:DECODER_01.CHANNEL_5:REPEAT_COUNT',\n",
    "    '\\\\RFX::TOP.RFX.DIAG.DTER.DTER_RAW.TIMING:DECODER_01.CHANNEL_5:SPECIAL_GATE',\n",
    "    '\\\\RFX::TOP.RFX.DIAG.DTER.DTER_RAW.TIMING:K3115_01.CHANNEL_01:VOLTAGES',\n",
    "    '\\\\RFX::TOP.RFX.DIAG.DTER.DTER_RAW.TIMING:K3115_01.CHANNEL_01:TIME_MODE',\n",
    "    '\\\\RFX::TOP.RFX.DIAG.DTER.DTER_RAW.TIMING:DECODER_01.CHANNEL_5:LOAD',\n",
    "    '\\\\RFX::TOP.RFX.DIAG.DTER.DTER_RAW.TIMING:K3115_01.CHANNEL_02:OUTPUT',\n",
    "    '\\\\RFX::TOP.RFX.DIAG.DTER.DTER_RAW.TIMING:K3115_01.CHANNEL_02:VOLTAGES',\n",
    "    '\\\\RFX::TOP.RFX.MHD.MHD_BR:CPCI_1:ADC:TR10_11:CLOCK_SOURCE',\n",
    "    '\\\\RFX::TOP.RFX.MHD.MHD_BR:CPCI_1:ADC:TR10_12:CLOCK_SOURCE',\n",
    "    '\\\\RFX::TOP.RFX.MHD.MHD_BR:CPCI_1:ADC:TR10_2:CLOCK_SOURCE',\n",
    "    '\\\\RFX::TOP.RFX.MHD.MHD_BR:CPCI_1:ADC:TR10_3:CLOCK_SOURCE',\n",
    "    '\\\\RFX::TOP.RFX.MHD.MHD_BR:CPCI_1:ADC:TR10_4:CLOCK_SOURCE',\n",
    "    '\\\\RFX::TOP.RFX.MHD.MHD_BR:CPCI_1:ADC:TR10_5:CLOCK_SOURCE',\n",
    "    '\\\\RFX::TOP.RFX.MHD.MHD_BR:CPCI_1:ADC:TR10_6:CLOCK_SOURCE',\n",
    "    '\\\\RFX::TOP.RFX.MHD.MHD_BR:CPCI_1:ADC:TR10_7:CLOCK_SOURCE',\n",
    "    '\\\\RFX::TOP.RFX.MHD.MHD_BR:CPCI_1:ADC:TR10_8:CLOCK_SOURCE',\n",
    "    '\\\\RFX::TOP.RFX.MHD.MHD_BR:CPCI_1:ADC:TR10_9:CLOCK_SOURCE',\n",
    "    '\\\\RFX::TOP.RFX.MHD.MHD_BR:CPCI_1:TIMING:DIO2_1.CHANNEL_1:CLOCK',\n",
    "]\n",
    "\n",
    "# check that the nodes exist\n",
    "for snpath in SEG_FAULT_NODES:\n",
    "    try: n = rfx.getNode(snpath); assert snpath == str(n.getFullPath())\n",
    "    except: print(f'{snpath} does not exist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's do the same but without recursion\n",
    "MAX_DEPTH = 64\n",
    "with h5.File(HDF5_FILE, 'w') as hdf:\n",
    "    skipped_nodes = 0\n",
    "    def explore_tree(start_node=rfx.getNode('\\\\TOP.RFX'), max_depth=4):\n",
    "        curr_nodes = [start_node]\n",
    "        for d in range(max_depth):\n",
    "            next_nodes = []\n",
    "            # for node in tqdm(curr_nodes, desc=f'Depth {d}:'):\n",
    "            for node in curr_nodes:\n",
    "                npath = str(node.getFullPath())\n",
    "                print(f'{npath}')\n",
    "                if npath in SEG_FAULT_NODES: print(f'{ERR}Skipping {npath}{ENDC}'); continue\n",
    "                npath = npath[10:].replace('.', '/').replace(':', '/')\n",
    "                length = node.length # length of data in bytes, uncompressed\n",
    "                if length > 10_000_000: print(f'{WARN}NODE {npath} has length {length}{ENDC}')\n",
    "                if length > 100_000_000: print(f'{ERR}NODE {npath} has length {length}{ENDC}'); continue\n",
    "                \n",
    "                is_child = node.isChild()\n",
    "                is_member = node.isMember()\n",
    "                assert (is_child or is_member) and not (is_child and is_member)\n",
    "                has_children = hasChildren(node)\n",
    "                has_members = hasMembers(node)\n",
    "                has_time = hasTime(node)\n",
    "                has_data = hasData(node)\n",
    "                nname = node.node_name.upper() if is_child else node.node_name.lower()\n",
    "                nusage = str(node.usage)\n",
    "                \n",
    "                # if has_children or has_members: \n",
    "                #     group = hdf.create_group(npath)  \n",
    "                #     group.attrs['usage'] = nusage  \n",
    "                    \n",
    "                if has_data and has_children: print(f'{ERR}NODE {npath} has DATA and CHILDREN: data: {node.data()}, CHILDREN: {node.getChildren()}{ENDC}')\n",
    "                if has_data and has_members: print(f'{WARN}node {npath} has data and members: data: {node.data()}, members: {node.getMembers()}{ENDC}')\n",
    "                \n",
    "                # if has_data: # save the data to the hdf5 file\n",
    "                #     data = node.data()\n",
    "                #     hdf.create_dataset(path, data=data)\n",
    "                \n",
    "                if has_children:\n",
    "                    for child in node.getChildren(): next_nodes.append(child)\n",
    "                if has_members:\n",
    "                    for member in node.getMembers(): next_nodes.append(member)                \n",
    "            curr_nodes = next_nodes\n",
    "\n",
    "    # top_nodes = [\"MHD.MHD_BR\",\"MHD\", \"SETUP\", \"STC\", \"VERSIONS\"]\n",
    "    # for tn in top_nodes:\n",
    "    #     print(f'\\nTop node: {tn}\\n')\n",
    "    #     explore_tree(rfx.getNode(f'\\\\TOP.RFX.{tn}'), MAX_DEPTH)\n",
    "    #     print(f'\\n{tn} FINISHED\\n=================================\\n=================================\\n=================================\\n')\n",
    "    \n",
    "    explore_tree(rfx.getNode('\\\\TOP.RFX'), MAX_DEPTH)    \n",
    "                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the tree structure\n",
    "def h5_tree(vals, pre='', mid_syms=('├────','│     '), end_syms=('└────','      ')):\n",
    "    for i, (key, val) in enumerate(vals.items()):\n",
    "        s1, s2 = end_syms if i == len(vals)-1 else mid_syms\n",
    "        if type(val) == h5.Group: \n",
    "            print(f'{pre}{s1} {key}') \n",
    "            h5_tree(val, f'{pre}{s2}', mid_syms, end_syms)\n",
    "        else: print(f'{pre}{s1} {key} [{val.shape} {val.dtype}]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5.File(HDF5_FILE, 'r') as f: h5_tree(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
